{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "exec(open(\"../database.py\").read())\n",
    "exec(open(\"../helperFunctions.py\").read())\n",
    "import pandas as pd\n",
    "from keras.datasets import mnist\n",
    "import math\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Prepare dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTrueDatasets (name, metric, queries) :\n",
    "    datasetTrainImages, datasetTestImages, _ = get_ann_benchmark_data(name)\n",
    "    index = faiss.IndexFlatL2(datasetTrainImages.shape[1])   # take basic index\n",
    "    print('index.is_trained : ', index.is_trained)\n",
    "\n",
    "    index.add(datasetTrainImages) # add vectors to the index\n",
    "    print('index.ntotal : ', index.ntotal)\n",
    "\n",
    "    D = []\n",
    "    I = []\n",
    "    def createTrueLabels(par, D, I, datasetTestImages):\n",
    "        k = 100\n",
    "        totalTime = 0\n",
    "        for i in range(par) : \n",
    "            xq = datasetTestImages[i:i+1] # Use the first image as the query vector\n",
    "            time_start = perf_counter()\n",
    "            x, y = index.search(xq, k)\n",
    "            time_end = perf_counter()\n",
    "            totalTime += (time_end - time_start)\n",
    "            D.append(np.sqrt(x[0]))\n",
    "            I.append(y[0])\n",
    "        print(totalTime)\n",
    "        indexes = np.array(I)\n",
    "        distances = np.array(D)\n",
    "        naming = name + '-' + metric + '-true-labels.xlsx'\n",
    "        exportDB(indexes, distances, naming, 1)\n",
    "        \n",
    "    createTrueLabels(queries, D, I, datasetTestImages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Учеба\\Назарбаев Университет\\Masters\\raAndThesis\\PavelBraslavski\\annSearchComparisons/datasets/deepImage-96.hdf5\n",
      "Dataset deepImage-96 is not cached; downloading now ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:90: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainDataset :  (9990000, 96)\n",
      "testDataset :  (10000, 96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:91: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "<string>:92: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n"
     ]
    }
   ],
   "source": [
    "datasets_list = ['deepImage-96', 'fashionMnist-784', 'gist-960', 'glove-25', 'glove-50', 'glove-100', 'glove-200', 'mnist-784', 'nytimes-256', 'sift-128', 'lastfm-64']\n",
    "specialDatasets = ['kosarak', 'movielens10m']\n",
    "examle = ['mnist-784']\n",
    "metrics = ['euclidean']\n",
    "queries = 1000\n",
    "for j in metrics:\n",
    "    for i in datasets_list:\n",
    "        createTrueDatasets(i, j, queries)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
