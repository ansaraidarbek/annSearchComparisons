{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "exec(open(\"../database.py\").read())\n",
    "exec(open(\"../helperFunctions.py\").read())\n",
    "import pandas as pd\n",
    "from keras.datasets import mnist\n",
    "import math\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Prepare dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTrueDatasets (name, metric, queries) :\n",
    "    datasetTrainImages, datasetTestImages, _ = get_ann_benchmark_data(name)\n",
    "    index = faiss.IndexFlatL2(datasetTrainImages.shape[1])   # take basic index\n",
    "    print('index.is_trained : ', index.is_trained)\n",
    "\n",
    "    index.add(datasetTrainImages) # add vectors to the index\n",
    "    print('index.ntotal : ', index.ntotal)\n",
    "\n",
    "    D = []\n",
    "    I = []\n",
    "    def createTrueLabels(par, D, I, datasetTestImages):\n",
    "        k = 100\n",
    "        totalTime = 0\n",
    "        for i in range(par) : \n",
    "            xq = datasetTestImages[i:i+1] # Use the first image as the query vector\n",
    "            time_start = perf_counter()\n",
    "            x, y = index.search(xq, k)\n",
    "            time_end = perf_counter()\n",
    "            totalTime += (time_end - time_start)\n",
    "            D.append(np.sqrt(x[0]))\n",
    "            I.append(y[0])\n",
    "        print(totalTime)\n",
    "        indexes = np.array(I)\n",
    "        distances = np.array(D)\n",
    "        naming = name + '-' + metric + '-true-labels.xlsx'\n",
    "        exportDB(indexes, distances, naming, 1)\n",
    "        \n",
    "    createTrueLabels(queries, D, I, datasetTestImages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Учеба\\Назарбаев Университет\\Masters\\raAndThesis\\PavelBraslavski\\annSearchComparisons/datasets/mnist-784.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:84: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainDataset :  (60000, 784)\n",
      "testDataset :  (10000, 784)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:85: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "<string>:86: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index.is_trained :  True\n",
      "index.ntotal :  60000\n",
      "65.77814959999995\n",
      "indexes :  (1000, 100)\n",
      "distances :  (1000, 100)\n",
      "(1000, 2)\n",
      "<bound method NDFrame.head of                                                Indexes  \\\n",
      "0    [53843, 38620, 16186, 27059, 47003, 14563, 445...   \n",
      "1    [28882, 49160, 24612, 31634, 16902, 17757, 319...   \n",
      "2    [58741, 46512, 15224, 47333, 44038, 42531, 393...   \n",
      "3    [29044, 59244, 34523, 32708, 1877, 48807, 2327...   \n",
      "4    [52920, 40094, 50609, 25760, 32719, 53519, 247...   \n",
      "..                                                 ...   \n",
      "995  [2065, 11615, 22236, 23610, 39249, 11017, 1010...   \n",
      "996  [2936, 50991, 6992, 28566, 21207, 24406, 38417...   \n",
      "997  [53387, 48523, 44720, 51331, 23093, 11281, 244...   \n",
      "998  [7300, 54916, 42832, 47634, 3928, 32926, 19396...   \n",
      "999  [3104, 43862, 29108, 4747, 58096, 50473, 36420...   \n",
      "\n",
      "                                             Distances  \n",
      "0    [676.584, 793.9868, 862.6766, 864.5039, 894.7,...  \n",
      "1    [1162.9316, 1211.8445, 1285.9285, 1292.1184, 1...  \n",
      "2    [321.6629, 332.4635, 341.0484, 367.7146, 377.3...  \n",
      "3    [1221.5825, 1228.2321, 1238.3389, 1251.6489, 1...  \n",
      "4    [1092.5347, 1096.0457, 1169.3439, 1171.8759, 1...  \n",
      "..                                                 ...  \n",
      "995  [1663.3911, 1672.9255, 1709.6702, 1713.7788, 1...  \n",
      "996  [1208.5392, 1243.3737, 1302.3936, 1318.7247, 1...  \n",
      "997  [1218.7662, 1225.202, 1281.5635, 1282.1864, 12...  \n",
      "998  [1660.3867, 1773.5786, 1842.6809, 1887.7446, 1...  \n",
      "999  [1086.8597, 1147.9011, 1220.3807, 1223.4583, 1...  \n",
      "\n",
      "[1000 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "datasets_list = ['deepImage-96', 'fashionMnist-784', 'gist-960', 'glove-25', 'glove-50', 'glove-100', 'glove-200', 'mnist-784', 'nytimes-256', 'sift-128', 'lastfm-64']\n",
    "specialDatasets = ['kosarak', 'movielens10m']\n",
    "examle = ['mnist-784']\n",
    "metrics = ['euclidean']\n",
    "queries = 1000\n",
    "for j in metrics:\n",
    "    for i in datasets_list:\n",
    "        createTrueDatasets(i, j, queries)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
